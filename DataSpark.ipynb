{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\capstone project-2\\Customers_updated.csv\", 'rb') as f:\n",
    "       rawdata = f.read()\n",
    "       result = chardet.detect(rawdata)\n",
    "       encoding = result['encoding']\n",
    "\n",
    "print(\"Detected Encoding:\", encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers=pd.read_csv(r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\capstone project-2\\Customers_updated.csv\",skipinitialspace=True,engine='python')\n",
    "#data_dictionary=pd.read_csv(r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\capstone project-2\\Data_Dictionary.csv\",skipinitialspace=True,engine='python')\n",
    "products = pd.read_csv(r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\capstone project-2\\Products_updated.csv\",skipinitialspace=True,engine='python')\n",
    "sales = pd.read_csv(r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\capstone project-2\\Sales_updated.csv\",skipinitialspace=True,engine='python')\n",
    "stores = pd.read_csv(r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\capstone project-2\\Stores_updated.csv\",skipinitialspace=True,engine='python')\n",
    "exchange_rates = pd.read_csv(r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\capstone project-2\\Exchange_Rates_updated.csv\",skipinitialspace=True,engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['Birthday']=pd.to_datetime(customers['Birthday'])\n",
    "customers.head()\n",
    "\n",
    "customers['Zip Code'] = pd.to_numeric(customers['Zip Code'], errors='coerce').astype('Int64')  # Use 'Int64' for nullable integer type\n",
    "print(customers['Zip Code'].dtypes)\n",
    "\n",
    "has_nan = customers.isna().any().any()\n",
    "\n",
    "rows_with_nan = customers[customers.isna().any(axis=1)]\n",
    "print(f\"Rows with NaN values:\\n{rows_with_nan}\")\n",
    "\n",
    "customers.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_nan = data_dictionary.isna().any().any()\n",
    "has_nan\n",
    "data_dictionary['Field'] = data_dictionary['Field'].astype(str)\n",
    "print(data_dictionary['Field'].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_convert(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    # Remove non-numeric characters (e.g., $, spaces)\n",
    "    cleaned_value = ''.join(filter(str.isdigit, str(value).replace('.', '')))\n",
    "    if cleaned_value:\n",
    "        return pd.to_numeric(cleaned_value, errors='coerce')\n",
    "    return None\n",
    "\n",
    "has_nan = products.isna().any().any()\n",
    "has_nan\n",
    "\n",
    "products['Unit Price USD'] = products['Unit Price USD'].apply(clean_and_convert)\n",
    "products['Unit Price USD'] = pd.to_numeric(products['Unit Price USD'], errors='coerce').astype('Int64')\n",
    "\n",
    "print(products['SubcategoryKey'].dtypes)\n",
    "\n",
    "products.to_csv(r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\capstone project-2\\Products_updated.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales=pd.read_csv(r\"C:\\Users\\surej.r\\OneDrive - IDP Education Ltd\\Desktop\\project\\Sales.csv\",encoding='ascii') \n",
    "duplicates_specific = sales[sales.duplicated(subset=['Order Number','CustomerKey','ProductKey'])] \n",
    "duplicates_specific \n",
    "len(duplicates_specific) \n",
    "df_cleaned = sales.drop_duplicates(subset=['Order Number','CustomerKey','StoreKey'])\n",
    "print(df_cleaned.isna().sum()) \n",
    "df_cleaned['Delivery Date'] = pd.to_datetime(df_cleaned['Delivery Date'], errors='coerce') \n",
    "df_cleaned['Delivery Date'] = df_cleaned['Delivery Date'].fillna(method='bfill') \n",
    "df_cleaned['Order Date'] = pd.to_datetime(df_cleaned['Order Date'], errors='coerce') \n",
    "df_cleaned.to_csv(r'C:\\Users\\surej.r\\OneDrive - IDP Education Ltd\\Desktop\\project\\Sales_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exchange_Rates=pd.read_csv(r\"C:\\Users\\surej.r\\OneDrive - IDP Education Ltd\\Desktop\\project\\Exchange_Rates.csv\",encoding='ascii') \n",
    "duplicates_specific = Exchange_Rates[Exchange_Rates.duplicated(subset=['Date','Currency'])] \n",
    "duplicates_specific \n",
    "#len(duplicates_specific) \n",
    "Exchange_Rates['Date'] = pd.to_datetime(Exchange_Rates['Date'], errors='coerce') \n",
    "Exchange_Rates.to_csv(r'C:\\Users\\surej.r\\OneDrive - IDP Education Ltd\\Desktop\\project\\Exchange_Rates_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stores=pd.read_csv(r\"C:\\Users\\surej.r\\OneDrive - IDP Education Ltd\\Desktop\\project\\Stores.csv\",encoding='utf-8') \n",
    "print(Stores.isna().sum()) \n",
    "Stores['Square Meters'].fillna(Stores['Square Meters'].mean()) \n",
    "mean_values = Stores['Square Meters'].min() Stores = Stores.fillna(mean_values) \n",
    "mean_values \n",
    "duplicates_specific = Stores[Stores.duplicated(subset=['StoreKey'])] \n",
    "duplicates_specific \n",
    "#len(duplicates_specific) \n",
    "Stores['Open Date'] = pd.to_datetime(Stores['Open Date'], errors='coerce') \n",
    "Stores.to_csv(r'C:\\Users\\surej.r\\OneDrive - IDP Education Ltd\\Desktop\\project\\Stores_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = sales.merge(customers, on='CustomerKey') \\\n",
    "                   .merge(products, on='ProductKey') \\\n",
    "                   .merge(stores, on='StoreKey') \\\n",
    "                   .merge(exchange_rates, left_on=['Currency Code', 'Order Date'], right_on=['Currency', 'Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data=merged_data.drop(columns=['Currency Code','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv(r'C:\\Users\\surej\\OneDrive\\Desktop\\project\\capstone project-2\\merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('DataSpark.db')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "for i in cursor:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''\n",
    "    CREATE TABLE customers (\n",
    "        CustomerKey INT PRIMARY KEY,\n",
    "        Gender VARCHAR,\n",
    "        Name VARCHAR,\n",
    "        City VARCHAR,\n",
    "        State_Code VARCHAR,\n",
    "        state VARCHAR,\n",
    "        Zip_Code INT,\n",
    "        country VARCHAR,\n",
    "        continent VARCHAR,\n",
    "        Birthday DATE\n",
    "    );\n",
    "    ''')\n",
    "\n",
    "df=pd.read_csv(r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\capstone project-2\\Customers_updated.csv\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sql = '''\n",
    "        INSERT INTO customers (CustomerKey, Gender, Name,City,State_Code,state,Zip_Code,country,continent,Birthday)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    '''\n",
    "    cursor.execute(sql, tuple(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''\n",
    "    CREATE TABLE Exchange_Rate (\n",
    "        Date DATE,\n",
    "        Currency VARCHAR,\n",
    "        Exchange FLOAT\n",
    "    );\n",
    "    ''')\n",
    "\n",
    "df=pd.read_csv(r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\capstone project-2\\Exchange_Rates_updated.csv\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sql = '''\n",
    "        INSERT INTO Exchange_Rate (Date, Currency, Exchange)\n",
    "        VALUES (?, ?, ?)\n",
    "    '''\n",
    "    cursor.execute(sql, tuple(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''\n",
    "    CREATE TABLE products (\n",
    "        ProductKey INT PRIMARY KEY,\n",
    "        Product_Name VARCHAR,\n",
    "        Brand VARCHAR,\n",
    "        Color VARCHAR,\n",
    "        Unit Cost USD INT,\n",
    "        Unit Price USD INT,\n",
    "        SubcategoryKey INT,\n",
    "        Subcategory VARCHAR,\n",
    "        CategoryKey INT,\n",
    "        Category VARCHAR\n",
    "    );\n",
    "    ''')\n",
    "\n",
    "df=pd.read_csv(r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\capstone project-2\\Products_updated.csv\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sql = '''\n",
    "        INSERT INTO products (ProductKey, Product_Name, Brand,Color,Unit_Cost_USD,Unit_Price_USD,SubcategoryKey,Subcategory,CategoryKey,Category)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    '''\n",
    "    cursor.execute(sql, tuple(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''\n",
    "    CREATE TABLE stores (\n",
    "        StoreKey INT PRIMARY KEY,\n",
    "        Country VARCHAR,\n",
    "        State VARCHAR,\n",
    "        Square_Meter INT,\n",
    "        Open_Date DATE\n",
    "    );\n",
    "    ''')\n",
    "df=pd.read_csv(r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\capstone project-2\\Stores_updated.csv\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sql = '''\n",
    "        INSERT INTO stores (StoreKey, Country, State, Square_Meter,Open_Date )\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "    '''\n",
    "    cursor.execute(sql, tuple(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''\n",
    "    CREATE TABLE sales (\n",
    "        Order_Number INT PRIMARY KEY,\n",
    "        Line_Item INT,\n",
    "        Order_Date DATE,\n",
    "        Delivery_Date DATE,\n",
    "        CustomerKey INT,\n",
    "        StoreKey INT,\n",
    "        ProductKey INT,\n",
    "        Quantity INT,\n",
    "        Currency_Code VARCHAR,\n",
    "        FOREIGN KEY (CustomerKey) REFERENCES customers(CustomerKey),\n",
    "        FOREIGN KEY (StoreKey) REFERENCES stores(StoreKey),\n",
    "        FOREIGN KEY (ProductKey) REFERENCES products(ProductKey)\n",
    "\n",
    "    );\n",
    "    ''')\n",
    "\n",
    "df=pd.read_csv(r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\capstone project-2\\Sales_updated.csv\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sql = '''\n",
    "        INSERT INTO sales (Order_Number, Line_Item, Order_Date,Delivery_Date,CustomerKey,StoreKey,ProductKey,Quantity,Currency_Code)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    '''\n",
    "    cursor.execute(sql, tuple(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''\n",
    "    CREATE TABLE merged_data (\n",
    "        Order_Number INT PRIMARY KEY,\n",
    "        Line_Item INT,\n",
    "        Order_Date DATE,\n",
    "        Delivery_Date DATE,\n",
    "        CustomerKey INT,\n",
    "        StoreKey INT,\n",
    "        ProductKey INT,\n",
    "        Quantity INT,\n",
    "        Gender VARCHAR,\n",
    "        Name VARCHAR,\n",
    "        City VARCHAR,\n",
    "        State_Code VARCHAR,\n",
    "        state VARCHAR,\n",
    "        Zip_Code INT,\n",
    "        country VARCHAR,\n",
    "        continent VARCHAR,\n",
    "        Birthday DATE,\n",
    "        Product_Name VARCHAR,\n",
    "        Brand VARCHAR,\n",
    "        Color VARCHAR,\n",
    "        Unit_Cost_USD INT,\n",
    "        Unit_Price_USD INT,\n",
    "        SubcategoryKey INT,\n",
    "        Subcategory VARCHAR,\n",
    "        CategoryKey INT,\n",
    "        Category VARCHAR,\n",
    "        Country_y VARCHAR,\n",
    "        State_y VARCHAR,\n",
    "        Square_Meters INT,\n",
    "        Open_Date DATE,\n",
    "        Currency VARHAR,\n",
    "        Exchange FLOAT\n",
    "\n",
    "    );\n",
    "    ''')\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\surej\\OneDrive\\Desktop\\project\\capstone project-2\\merged_data.csv\")\n",
    "\n",
    "# Insert each row into the 'merged_data' table\n",
    "for index, row in df.iterrows():\n",
    "    sql = '''\n",
    "        INSERT INTO merged_data (Order_Number, Line_Item, Order_Date, Delivery_Date, CustomerKey, StoreKey, ProductKey, Quantity, Gender, Name, City, State_Code, state, Zip_Code, country, continent, Birthday, Product_Name, Brand, Color, Unit_Cost_USD, Unit_Price_USD, SubcategoryKey, Subcategory, CategoryKey, Category, Country_y, State_y, Square_Meters, Open_Date, Currency, Exchange)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    '''\n",
    "    cursor.execute(sql, tuple(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"select * from Exchange_Rate limit 5\")\n",
    "for i in cursor:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"drop table Exchange_Rates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".vene",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
